{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19827b1e",
   "metadata": {},
   "source": [
    "## ***DIPLOMADO EN CIENCIA DE DATOS APLICADOS AL DESARROLLO INTEGRAL DEL TALENTO HUMANOX***  \n",
    "\n",
    "### ***M4: An√°lisis Predictivo para la Toma de Decisiones Estrat√©gicas en RRHH***  \n",
    "\n",
    "### ***<span style=\"color:#FF0000\">Universidad del Rosario</span>***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f6293",
   "metadata": {},
   "source": [
    "# üìò Notebook 2 ‚Äì Predicci√≥n de Competencias Blandas en RRHH\n",
    "\n",
    "En este notebook trabajaremos con un dataset de Recursos Humanos adaptado con variables que representan atributos de los colaboradores en una organizaci√≥n.  \n",
    "\n",
    "El objetivo ahora ser√° aplicar t√©cnicas de **regresi√≥n lineal** para predecir el nivel de **competencias blandas** a partir de otras caracter√≠sticas de los empleados.\n",
    "\n",
    "## üìÇ Estructura del Dataset\n",
    "\n",
    "El dataset contiene informaci√≥n de colaboradores descrita con las siguientes variables:\n",
    "\n",
    "- **A√±os de experiencia**: tiempo acumulado en el mercado laboral.  \n",
    "- **Formaci√≥n continua**: nivel de educaci√≥n y capacitaci√≥n permanente.  \n",
    "- **Competencias t√©cnicas**: habilidades asociadas al desempe√±o profesional espec√≠fico.  \n",
    "- **Competencias blandas**: habilidades sociales, comunicativas y de liderazgo (variable a predecir).  \n",
    "- **Perfil de talento**: clasificaci√≥n del empleado (ej. *Innovador, Ejecutor, Tradicionalista*).  \n",
    "\n",
    "## üéØ Objetivos del Notebook\n",
    "- Construir un modelo de **regresi√≥n lineal** para predecir las competencias blandas.  \n",
    "- Evaluar el desempe√±o del modelo con m√©tricas de regresi√≥n (MAE, RMSE, R¬≤).  \n",
    "- Visualizar la relaci√≥n entre valores reales y valores predichos.  \n",
    "- Reflexionar sobre el potencial y limitaciones de aplicar modelos de regresi√≥n en datos de Recursos Humanos.  \n",
    "\n",
    "## üõ†Ô∏è Herramientas a utilizar\n",
    "- **pandas** y **numpy**: manipulaci√≥n de datos.  \n",
    "- **matplotlib** y **seaborn**: visualizaci√≥n de resultados.  \n",
    "- **scikit-learn**: construcci√≥n y evaluaci√≥n del modelo de regresi√≥n lineal.  \n",
    "\n",
    "‚û°Ô∏è Al finalizar este notebook, tendr√°s un **modelo predictivo capaz de estimar el nivel de competencias blandas** de un colaborador en funci√≥n de sus caracter√≠sticas de experiencia, formaci√≥n y competencias t√©cnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de librer√≠as necesarias\n",
    "# \n",
    "# En esta celda instalamos las principales librer√≠as que usaremos a lo largo del notebook:\n",
    "# - pandas: para manipulaci√≥n y an√°lisis de datos.\n",
    "# - numpy: para operaciones num√©ricas y manejo de arreglos.\n",
    "# - matplotlib: para visualizaciones b√°sicas.\n",
    "# - seaborn: para visualizaciones estad√≠sticas m√°s estilizadas.\n",
    "# - scikit-learn: para construir y evaluar modelos de machine learning.\n",
    "#\n",
    "# Esta celda solo necesita ejecutarse una vez (o cuando el entorno no tenga estas librer√≠as instaladas).\n",
    "\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as necesarias\n",
    "\n",
    "# üîπ Manipulaci√≥n y an√°lisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# üîπ Visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# üîπ Preprocesamiento y modelado\n",
    "from sklearn.model_selection import train_test_split   # Divisi√≥n en train y test\n",
    "from sklearn.linear_model import LinearRegression      # Modelo de regresi√≥n lineal\n",
    "\n",
    "# üîπ Evaluaci√≥n del modelo\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecaf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Cargar dataset\n",
    "url = \"https://raw.githubusercontent.com/LeStark/Cursos/refs/heads/main/Data/iris_human_resources.csv\"\n",
    "df = pd.read_csv(url, sep=\",\")\n",
    "df.info()  # Informaci√≥n del dataset\n",
    "df.head()  # Mostrar las primeras filas del dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versi√≥n PairGrid\n",
    "\n",
    "g = sns.PairGrid(df, hue=\"Perfil de talento\")\n",
    "g.map_diag(sns.histplot, kde=False)  # Histogramas en la diagonal\n",
    "g.map_offdiag(sns.scatterplot, alpha=0.7)  # Scatter plots fuera de la diagonal\n",
    "g.add_legend()  # Agregar leyenda\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033eb203",
   "metadata": {},
   "source": [
    "##  An√°lisis del Pairplot: ¬øTiene sentido aplicar Regresi√≥n Lineal para predecir Competencias Blandas?\n",
    "\n",
    "Al observar el *pairplot* que relaciona las diferentes variables del dataset de RRHH, podemos destacar lo siguiente:\n",
    "\n",
    "### 1. A√±os de experiencia vs. Competencias blandas\n",
    "Existe una relaci√≥n positiva, aunque no perfectamente lineal. \n",
    "Se observa que los colaboradores clasificados como **Tradicionalistas** tienden a concentrarse en valores m√°s altos tanto de experiencia como de competencias blandas.\n",
    "\n",
    "### 2. Formaci√≥n continua vs. Competencias blandas\n",
    "La relaci√≥n es m√°s dispersa, pero se aprecia una ligera tendencia creciente. \n",
    "Esto sugiere que la formaci√≥n continua podr√≠a aportar cierta capacidad predictiva, aunque no tan fuerte como otras variables.\n",
    "\n",
    "### 3. Competencias t√©cnicas vs. Competencias blandas\n",
    "Aqu√≠ encontramos la relaci√≥n m√°s clara: **una correlaci√≥n positiva fuerte y casi lineal**.\n",
    "Los empleados con mayor nivel de competencias t√©cnicas suelen presentar tambi√©n mayores competencias blandas.\n",
    "\n",
    "###  Implicaciones para aplicar Regresi√≥n Lineal\n",
    "- La **fuerte relaci√≥n lineal entre competencias t√©cnicas y competencias blandas** respalda la pertinencia de usar un modelo de regresi√≥n lineal.  \n",
    "- Incluir **a√±os de experiencia** y **formaci√≥n continua** como predictores adicionales puede aportar informaci√≥n complementaria, aunque su relaci√≥n con la variable objetivo sea menos evidente.  \n",
    "- La regresi√≥n lineal es un buen punto de partida: sencilla de interpretar, r√°pida de entrenar y √∫til como modelo de referencia (*baseline*).  \n",
    "\n",
    "### Consideraciones\n",
    "- La relaci√≥n no es perfectamente lineal en todas las variables, por lo que habr√° cierto nivel de error.  \n",
    "- Es posible que modelos m√°s complejos (ej. Random Forest, SVR) capturen mejor las relaciones no lineales.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845c0b9",
   "metadata": {},
   "source": [
    "## Preparaci√≥n de los datos para el modelado\n",
    "\n",
    "Antes de construir un modelo predictivo es necesario preparar adecuadamente los datos.  \n",
    "En esta etapa realizamos los siguientes pasos:\n",
    "\n",
    "1. **Separaci√≥n de variables (features y target)**  \n",
    "   - **X**: incluye todas las caracter√≠sticas independientes (*a√±os de experiencia, formaci√≥n continua, competencias t√©cnicas*).  \n",
    "   - **y**: corresponde a la variable objetivo que deseamos predecir: *competencias blandas*.  \n",
    "   - La columna *Perfil de talento* se excluye porque en este escenario no ser√° usada como predictor.  \n",
    "\n",
    "2. **Normalizaci√≥n / Estandarizaci√≥n de las features**  \n",
    "   - Usamos `StandardScaler` para transformar todas las variables predictoras a la misma escala.  \n",
    "   - Cada variable queda con **media = 0** y **desviaci√≥n est√°ndar = 1**.  \n",
    "   - Esto evita que una variable con valores m√°s grandes (por ejemplo, *a√±os de experiencia*) domine sobre otras.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c7285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaci√≥n de los datos para modelado\n",
    "\n",
    "# 1. Separar features (X) y target (y)\n",
    "X = df.drop([\"Competencias blandas\",\"Perfil de talento\"], axis=1)   # Variables independientes\n",
    "y = df[\"Competencias blandas\"]               # Variable objetivo\n",
    "\n",
    "\n",
    "# 3. Normalizaci√≥n/Estandarizaci√≥n de las features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Verificaci√≥n de la transformaci√≥n\n",
    "print(\"\\nPrimeras 5 filas de las variables normalizadas:\")\n",
    "print(X_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790456a7",
   "metadata": {},
   "source": [
    "## Divisi√≥n del dataset\n",
    "\n",
    "Separamos los datos en **entrenamiento (75%)** y **prueba (25%)** usando `train_test_split`.  \n",
    "- El conjunto de entrenamiento sirve para que el modelo aprenda.  \n",
    "- El conjunto de prueba se reserva para evaluar su desempe√±o en datos no vistos.  \n",
    "- Con `random_state=42` garantizamos que la partici√≥n sea reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefcb594",
   "metadata": {},
   "source": [
    "## Construcci√≥n del modelo de Regresi√≥n Lineal\n",
    "\n",
    "Creamos una instancia del modelo `LinearRegression()` de *scikit-learn* y lo entrenamos con los datos de entrenamiento (`X_train`, `y_train`).  \n",
    "\n",
    "En esta etapa, el modelo aprende la relaci√≥n entre las variables predictoras (a√±os de experiencia, formaci√≥n continua, competencias t√©cnicas, etc.) y la variable objetivo (*competencias blandas*).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo de regresi√≥n lineal\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3beb4",
   "metadata": {},
   "source": [
    "## Predicciones\n",
    "\n",
    "Usamos el modelo entrenado para generar predicciones sobre el conjunto de prueba (`X_test`).  \n",
    "De esta forma obtenemos `y_pred`, que contiene los valores estimados de *competencias blandas* para los colaboradores que el modelo no hab√≠a visto antes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Predicciones\n",
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fd2c6",
   "metadata": {},
   "source": [
    "## Coeficientes (betas) del modelo\n",
    "\n",
    "En un modelo de **Regresi√≥n Lineal**, cada variable predictora tiene asociado un coeficiente Œ≤ (beta) que indica su influencia sobre la variable objetivo (*competencias blandas*).  \n",
    "\n",
    "- **Intercepto (Œ≤‚ÇÄ):** valor estimado de *competencias blandas* cuando todas las variables predictoras son cero.  \n",
    "- **Coeficientes (Œ≤‚ÇÅ, Œ≤‚ÇÇ, ‚Ä¶):** representan cu√°nto cambia el valor esperado de *competencias blandas* por cada unidad de aumento en la variable correspondiente, manteniendo las dem√°s constantes.  \n",
    "\n",
    "Al organizar los resultados en un DataFrame podemos identificar:  \n",
    "- Qu√© variables tienen mayor impacto en la predicci√≥n.  \n",
    "- Si su efecto es **positivo** (incrementan las competencias blandas) o **negativo** (las reducen).  \n",
    "\n",
    "Esto nos permite interpretar el modelo m√°s all√° de su precisi√≥n, entendiendo c√≥mo cada caracter√≠stica de los colaboradores contribuye a explicar su nivel de competencias blandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Obtener coeficientes (betas) del modelo\n",
    "betas = pd.DataFrame({\n",
    "    \"Variable\": X_train.columns,\n",
    "    \"Beta (coeficiente)\": lin_reg.coef_\n",
    "})\n",
    "\n",
    "print(\"Intercepto (Œ≤‚ÇÄ):\", lin_reg.intercept_)\n",
    "print(\"\\nBetas (coeficientes):\")\n",
    "print(betas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf2deb5",
   "metadata": {},
   "source": [
    "## üìè Evaluaci√≥n del modelo de regresi√≥n\n",
    "\n",
    "Una vez obtenidas las predicciones, debemos medir qu√© tan bien se ajusta nuestro modelo a los datos reales.  \n",
    "Para ello utilizamos varias m√©tricas de error y desempe√±o:\n",
    "\n",
    "- **MAE (Mean Absolute Error ‚Äì Error Absoluto Medio):**  \n",
    "  Promedio de las diferencias absolutas entre los valores reales y los predichos.  \n",
    "  Indica, en promedio, cu√°nto se equivoca el modelo en las unidades originales de la variable objetivo.  \n",
    "  Cuanto m√°s bajo, mejor.\n",
    "\n",
    "- **MSE (Mean Squared Error ‚Äì Error Cuadr√°tico Medio):**  \n",
    "  Promedio de los errores elevados al cuadrado.  \n",
    "  Penaliza con m√°s fuerza los errores grandes, por lo que es sensible a valores at√≠picos.  \n",
    "  Un valor bajo indica mejor ajuste.\n",
    "\n",
    "- **RMSE (Root Mean Squared Error ‚Äì Ra√≠z del Error Cuadr√°tico Medio):**  \n",
    "  Es la ra√≠z cuadrada del MSE, lo que devuelve el error en las mismas unidades que la variable objetivo.  \n",
    "  Es m√°s interpretable que el MSE y tambi√©n penaliza errores grandes.\n",
    "\n",
    "- **R¬≤ (Coeficiente de determinaci√≥n):**  \n",
    "  Mide qu√© proporci√≥n de la variabilidad de los datos es explicada por el modelo.  \n",
    "  Toma valores entre 0 y 1:  \n",
    "  - **1** significa que el modelo explica el 100% de la variabilidad.  \n",
    "  - **0** significa que el modelo no explica nada (equivalente a predecir siempre la media).  \n",
    "  Valores cercanos a 1 indican un modelo con buen poder predictivo.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59601c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaci√≥n del modelo\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e1f03",
   "metadata": {},
   "source": [
    "## Segunda versi√≥n del modelo: incluyendo *Perfil de talento*\n",
    "\n",
    "En la primera versi√≥n del modelo usamos √∫nicamente variables num√©ricas (*a√±os de experiencia, formaci√≥n continua y competencias t√©cnicas*) para predecir el nivel de *competencias blandas*.  \n",
    "\n",
    "Ahora repetiremos el proceso de modelado, pero esta vez **incluiremos la variable categ√≥rica *Perfil de talento*** como predictor.  \n",
    "\n",
    "Para poder usarla en el modelo, fue transformada mediante **One-Hot Encoding**, lo que gener√≥ nuevas columnas binarias (0/1) que representan cada perfil (*Ejecutor* y *Tradicionalista*, dejando a *Innovador* como categor√≠a de referencia).  \n",
    "\n",
    "El objetivo es evaluar si al a√±adir esta informaci√≥n el modelo logra un **mejor ajuste** y explica una mayor parte de la variabilidad de *competencias blandas*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee8934",
   "metadata": {},
   "source": [
    "## Transformaci√≥n de la variable categ√≥rica *Perfil de talento*\n",
    "\n",
    "Para poder incluir la variable **Perfil de talento** en un modelo de regresi√≥n, debemos convertirla en un formato num√©rico.  \n",
    "Si la codific√°ramos como n√∫meros simples (0, 1, 2), el modelo interpretar√≠a una relaci√≥n ordinal inexistente entre los perfiles, lo que introducir√≠a sesgos.  \n",
    "\n",
    "La soluci√≥n es aplicar **One-Hot Encoding**, que crea columnas binarias (0/1) para cada categor√≠a.  \n",
    "En nuestro caso, al aplicar `drop=\"first\"`, se elimin√≥ una categor√≠a de referencia para evitar la **multicolinealidad** (problema conocido como *dummy variable trap*).  \n",
    "\n",
    "### Pasos realizados en la celda:\n",
    "1. **Definici√≥n del encoder:**  \n",
    "   Se inicializa `OneHotEncoder` con `drop=\"first\"` y `sparse_output=False` para obtener un DataFrame denso y legible.  \n",
    "\n",
    "2. **Transformaci√≥n:**  \n",
    "   Se aplica el encoder sobre la columna *Perfil de talento*, generando un arreglo con variables dummy.  \n",
    "\n",
    "3. **Creaci√≥n del DataFrame codificado:**  \n",
    "   Se construye un DataFrame (`perfil_encoded_df`) con nombres de columnas claros como:  \n",
    "   - `Perfil de talento_Ejecutor`  \n",
    "   - `Perfil de talento_Tradicionalista`  \n",
    "\n",
    "4. **Concatenaci√≥n:**  \n",
    "   Se combinan las variables num√©ricas originales con las columnas dummy, resultando en `df_encoded`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#  One-Hot Encoding para la variable categ√≥rica \"Perfil de talento\"\n",
    "encoder = OneHotEncoder(drop=\"first\",sparse_output=False)  \n",
    "\n",
    "# Transformar la columna y convertir a DataFrame\n",
    "perfil_encoded = encoder.fit_transform(df[[\"Perfil de talento\"]])\n",
    "\n",
    "# Crear DataFrame con las variables dummy\n",
    "perfil_encoded_df = pd.DataFrame(\n",
    "    perfil_encoded,\n",
    "    columns=encoder.get_feature_names_out([\"Perfil de talento\"]),\n",
    "    index=df.index   # mantener alineaci√≥n con el DataFrame original\n",
    ")\n",
    "\n",
    "# Concatenar con el DataFrame original\n",
    "df_encoded = pd.concat([df.drop(\"Perfil de talento\", axis=1), perfil_encoded_df], axis=1)\n",
    "df_encoded.info()  # Informaci√≥n del DataFrame transformado\n",
    "df_encoded.head()  # Mostrar las primeras filas del DataFrame transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572e5bc",
   "metadata": {},
   "source": [
    "## Definici√≥n de variables y divisi√≥n del dataset\n",
    "\n",
    "En esta etapa preparamos los datos para el modelado:\n",
    "\n",
    "1. **Definir variables predictoras (X) y objetivo (y):**  \n",
    "   - **X** ‚Üí contiene todas las caracter√≠sticas num√©ricas, incluidas las dummies generadas con *One-Hot Encoding*.  \n",
    "   - **y** ‚Üí corresponde a la variable que queremos predecir: *competencias blandas*.  \n",
    "\n",
    "2. **Divisi√≥n en entrenamiento y prueba:**  \n",
    "   Utilizamos `train_test_split` para separar el dataset:  \n",
    "   - **75%** de los datos para entrenamiento (`X_train`, `y_train`).  \n",
    "   - **25%** para prueba (`X_test`, `y_test`).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7af55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X (variables predictoras) y y (variable objetivo)\n",
    "X = df_encoded.drop(\"Competencias blandas\", axis=1)   # Todas las variables excepto la target\n",
    "y = df_encoded[\"Competencias blandas\"]                # Variable a predecir\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,        # 25% para test, 75% para entrenamiento\n",
    "    random_state=42,       # Semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "# Verificamos tama√±os\n",
    "print(\"Tama√±o de X_train:\", X_train.shape)\n",
    "print(\"Tama√±o de X_test:\", X_test.shape)\n",
    "print(\"Tama√±o de y_train:\", y_train.shape)\n",
    "print(\"Tama√±o de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ad878",
   "metadata": {},
   "source": [
    "## Entrenamiento y predicciones\n",
    "\n",
    "Dividimos los datos en entrenamiento y prueba, entrenamos un modelo de **Regresi√≥n Lineal** y generamos predicciones sobre el conjunto de prueba.  \n",
    "Finalmente, creamos un DataFrame para comparar los valores reales de *competencias blandas* con los valores predichos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d905788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dividir en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# üèóÔ∏è Construir modelo de regresi√≥n lineal\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# üîÆ Predicciones\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Valor real (y_test)\": y_test.values,\n",
    "    \"Predicci√≥n (y_pred)\": y_pred\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec25c5",
   "metadata": {},
   "source": [
    "##  Evaluaci√≥n del modelo\n",
    "\n",
    "Calculamos m√©tricas de error (**MAE, MSE, RMSE**) y el coeficiente de determinaci√≥n (**R¬≤**) para medir la precisi√≥n y capacidad explicativa del modelo de regresi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Evaluaci√≥n del modelo\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(\"R¬≤:\", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
