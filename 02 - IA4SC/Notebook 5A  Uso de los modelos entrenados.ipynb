{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6f2987",
   "metadata": {},
   "source": [
    "#  IA para Redes de Suministro \n",
    "\n",
    "üë§ **Autor:** John Leonardo Vargas Mesa  \n",
    "üîó [LinkedIn](https://www.linkedin.com/in/leonardovargas/) | [GitHub](https://github.com/LeStark)  \n",
    "\n",
    "## üìÇ Repositorio en GitHub  \n",
    "- üìì **Notebooks:** [Acceder aqu√≠](https://github.com/LeStark/Cursos/tree/main/02%20-%20IA4SC)  \n",
    "- üìë **Data sets:** [Acceder aqu√≠](https://github.com/LeStark/Cursos/tree/main/00%20-%20Data/02%20-%20SC)  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173d806",
   "metadata": {},
   "source": [
    "# üìò Notebook 5A  Uso de los modelos entrenados\n",
    "\n",
    "# ü§ñ Notebook 5A ‚Äì Uso de los Modelos Entrenados\n",
    "\n",
    "Este notebook tiene como prop√≥sito mostrar c√≥mo **utilizar un modelo de an√°lisis de sentimientos previamente entrenado** para realizar predicciones sobre nuevos conjuntos de rese√±as.  \n",
    "A partir del modelo desarrollado en el *Notebook 05 ‚Äì Introducci√≥n al NLP*, se construye un flujo reproducible para limpiar, vectorizar y clasificar texto sin necesidad de reentrenar el modelo.\n",
    "\n",
    "## üß© **Contenido del Notebook**\n",
    "\n",
    "1. **Carga de los Modelos Entrenados:**  \n",
    "   Se importan los objetos generados durante el entrenamiento:  \n",
    "   - `sentiment_model.pkl` ‚Üí modelo de clasificaci√≥n entrenado.  \n",
    "   - `tfidf_vectorizer.pkl` ‚Üí vectorizador TF-IDF.  \n",
    "   - `label_encoder.pkl` ‚Üí codificador de etiquetas.  \n",
    "\n",
    "   Estos permiten replicar el proceso completo sin volver a ejecutar el entrenamiento.\n",
    "\n",
    "2. **Definici√≥n del Preprocesamiento:**  \n",
    "   Se implementa la misma funci√≥n `preprocess_text()` utilizada en el entrenamiento, que:\n",
    "   - Convierte texto a min√∫sculas.  \n",
    "   - Elimina caracteres no alfab√©ticos, n√∫meros y URLs.  \n",
    "   - Tokeniza, elimina *stopwords* y aplica lematizaci√≥n.  \n",
    "\n",
    "   Esto asegura la **consistencia** entre el entrenamiento y la inferencia.\n",
    "\n",
    "3. **Creaci√≥n de la Funci√≥n de Predicci√≥n (`predict_sentiment`):**  \n",
    "   Se desarrolla una funci√≥n integral que:\n",
    "   - Limpia y normaliza el texto.  \n",
    "   - Lo transforma con el vectorizador TF-IDF.  \n",
    "   - Predice el sentimiento con el modelo cargado.  \n",
    "   - Decodifica la salida num√©rica a etiquetas de texto (*positive*, *neutral*, *negative*).\n",
    "\n",
    "4. **Prueba del Modelo con Nuevas Rese√±as:**  \n",
    "   Se aplican ejemplos de texto reales para observar las predicciones y verificar que el modelo generaliza correctamente.\n",
    "\n",
    "5. **Aplicaci√≥n Masiva sobre un DataFrame:**  \n",
    "   Se carga un archivo CSV con rese√±as nuevas (`sample_amazon_reviews.csv`)  \n",
    "   y se aplica la funci√≥n `predict_sentiment()` sobre toda la columna `reviewText`, generando una nueva columna `predicted_sentiment`.\n",
    "\n",
    "\n",
    "## üéØ **Objetivo de Aprendizaje**\n",
    "\n",
    "El estudiante comprender√° c√≥mo **reutilizar modelos de NLP ya entrenados** y c√≥mo integrarlos en flujos de predicci√≥n para analizar grandes vol√∫menes de texto.  \n",
    "Adem√°s, aprender√° a mantener la coherencia del pipeline (preprocesamiento ‚Üí vectorizaci√≥n ‚Üí predicci√≥n ‚Üí decodificaci√≥n) al aplicar el modelo en nuevos contextos.\n",
    "\n",
    "## üßæ **Herramientas Utilizadas**\n",
    "- **joblib** ‚Üí para cargar los modelos y objetos guardados.  \n",
    "- **NLTK / spaCy** ‚Üí preprocesamiento del texto.  \n",
    "- **scikit-learn** ‚Üí vectorizaci√≥n y predicci√≥n.  \n",
    "- **pandas** ‚Üí manipulaci√≥n de datos.  \n",
    "\n",
    "üí° *Este notebook demuestra c√≥mo llevar un modelo de NLP desde su entrenamiento hasta su aplicaci√≥n pr√°ctica, preparando el terreno para integraciones en sistemas reales o aplicaciones de an√°lisis automatizado de texto.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c8ce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jlvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jlvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jlvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\jlvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import joblib\n",
    "\n",
    "# --- Procesamiento de texto ---\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# --- Descarga de recursos NLTK ---\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# --- Carga del modelo de lenguaje de spaCy ---\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe94983",
   "metadata": {},
   "source": [
    "### **Carga del Archivo de Rese√±as de Muestra**\n",
    "\n",
    "Se carga un archivo CSV con una muestra de 100 rese√±as de Amazon desde una URL p√∫blica de GitHub para realizar pruebas r√°pidas con el modelo entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0bfae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I opened the micro disc and adapter I did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased this product knowing there might b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bought October 7th. Passed away December 23rd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was an inexpensive way to get my Galaxy N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Works well, and fast, does everything it claim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  When I opened the micro disc and adapter I did...\n",
       "1  I purchased this product knowing there might b...\n",
       "2  Bought October 7th. Passed away December 23rd....\n",
       "3  This was an inexpensive way to get my Galaxy N...\n",
       "4  Works well, and fast, does everything it claim..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url= r\"https://raw.githubusercontent.com/LeStark/Cursos/refs/heads/main/00%20-%20Data/03%20-%20NLP/sample_amazon_reviews.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcb49eb",
   "metadata": {},
   "source": [
    "###  **Carga del Modelo y Creaci√≥n de la Funci√≥n de Predicci√≥n**\n",
    "\n",
    "En esta secci√≥n se cargan los objetos entrenados previamente para realizar predicciones sobre nuevas rese√±as de texto.  \n",
    "Estos objetos fueron generados durante la etapa de entrenamiento y se almacenaron en la carpeta `Models/`:\n",
    "\n",
    "- **`sentiment_model.pkl`** ‚Üí Modelo de clasificaci√≥n entrenado (Regresi√≥n Log√≠stica).  \n",
    "- **`tfidf_vectorizer.pkl`** ‚Üí Vectorizador TF-IDF que transforma el texto en representaciones num√©ricas.  \n",
    "- **`label_encoder.pkl`** ‚Üí Codificador de etiquetas que traduce las categor√≠as (*positive*, *neutral*, *negative*) a valores num√©ricos y viceversa.  \n",
    "\n",
    "Adem√°s, se define nuevamente la funci√≥n `preprocess_text()` para limpiar y normalizar el texto con el mismo proceso utilizado en el entrenamiento (min√∫sculas, eliminaci√≥n de ruido, tokenizaci√≥n, stopwords y lematizaci√≥n).\n",
    "\n",
    "Finalmente, la funci√≥n `predict_sentiment()` integra todo el flujo:\n",
    "1. Preprocesa el texto nuevo.  \n",
    "2. Lo transforma con el vectorizador TF-IDF original.  \n",
    "3. Predice el sentimiento utilizando el modelo entrenado.  \n",
    "4. Decodifica el resultado para obtener la etiqueta final (**positive**, **neutral** o **negative**).\n",
    "\n",
    "Esta funci√≥n permitir√° aplicar el modelo de an√°lisis de sentimientos sobre cualquier conjunto nuevo de rese√±as.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d91c61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Cargar los objetos entrenados ---\n",
    "\n",
    "model = joblib.load(\"Models/sentiment_model.pkl\")\n",
    "vectorizer = joblib.load(\"Models/tfidf_vectorizer.pkl\")\n",
    "le = joblib.load(\"Models/label_encoder.pkl\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# --- Funci√≥n de preprocesamiento (id√©ntica a la usada en el entrenamiento) ---\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "# --- Funci√≥n principal para predecir sentimiento ---\n",
    "def predict_sentiment(text):\n",
    "    \"\"\"\n",
    "    Recibe una rese√±a (o texto en bruto),\n",
    "    aplica el mismo preprocesamiento usado en el entrenamiento,\n",
    "    transforma el texto en vector TF-IDF y devuelve el sentimiento predicho.\n",
    "    \"\"\"\n",
    "    # 1Ô∏è Limpiar el texto\n",
    "    clean_text = preprocess_text(text)\n",
    "\n",
    "    # 2Ô∏è Vectorizar usando el TF-IDF original\n",
    "    vector = vectorizer.transform([clean_text])\n",
    "\n",
    "    # 3Ô∏è Predecir usando el modelo cargado\n",
    "    pred = model.predict(vector)\n",
    "\n",
    "    # 4Ô∏è Decodificar la etiqueta num√©rica\n",
    "    sentiment = le.inverse_transform(pred)[0]\n",
    "    \n",
    "    return sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf1789",
   "metadata": {},
   "source": [
    "### **Aplicaci√≥n del Modelo a Nuevas Rese√±as**\n",
    "\n",
    "Se aplica la funci√≥n `predict_sentiment()` a la columna `reviewText` del DataFrame para predecir el sentimiento de cada rese√±a y visualizar los primeros resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44f66de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I opened the micro disc and adapter I did...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I purchased this product knowing there might b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bought October 7th. Passed away December 23rd....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was an inexpensive way to get my Galaxy N...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Works well, and fast, does everything it claim...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText predicted_sentiment\n",
       "0  When I opened the micro disc and adapter I did...            positive\n",
       "1  I purchased this product knowing there might b...            negative\n",
       "2  Bought October 7th. Passed away December 23rd....            negative\n",
       "3  This was an inexpensive way to get my Galaxy N...            positive\n",
       "4  Works well, and fast, does everything it claim...            positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar la funci√≥n sobre una columna de un DataFrame\n",
    "data[\"predicted_sentiment\"] = data[\"reviewText\"].apply(predict_sentiment)\n",
    "\n",
    "# Ver resultados\n",
    "data[[\"reviewText\", \"predicted_sentiment\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data.iloc[1][\"reviewText\"])\n",
    "print(data.iloc[1][\"predicted_sentiment\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
