{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeerEoaCENM5"
   },
   "source": [
    "## ***DIPLOMADO EN CIENCIA DE DATOS APLICADOS AL DESARROLLO INTEGRAL DEL TALENTO HUMANOX***  \n",
    "\n",
    "### ***M4: An√°lisis Predictivo para la Toma de Decisiones Estrat√©gicas en RRHH***  \n",
    "\n",
    "### ***<span style=\"color:#FF0000\">Universidad del Rosario</span>***\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Notebook 1 ‚Äì Fundamentos del An√°lisis Predictivo en RRHH\n",
    "\n",
    "En este notebook trabajaremos con un dataset de Recursos Humanos adaptado con variables que representan atributos de los colaboradores en una organizaci√≥n.  \n",
    "\n",
    "Este ser√° nuestro punto de partida para aprender a **explorar, limpiar y preparar datos** con miras a usarlos en modelos predictivos.\n",
    "\n",
    "## üìÇ Estructura del Dataset\n",
    "\n",
    "El dataset contiene informaci√≥n de colaboradores descrita con las siguientes variables:\n",
    "\n",
    "- **A√±os de experiencia**: tiempo acumulado en el mercado laboral.  \n",
    "- **Formaci√≥n continua**: nivel de educaci√≥n y capacitaci√≥n permanente.  \n",
    "- **Competencias t√©cnicas**: habilidades asociadas al desempe√±o profesional espec√≠fico.  \n",
    "- **Competencias blandas**: habilidades sociales, comunicativas y de liderazgo.  \n",
    "- **Perfil de talento**: clasificaci√≥n del empleado (ej. *Innovador*, otros perfiles).  \n",
    "\n",
    "## üéØ Objetivos del Notebook\n",
    "- Realizar un an√°lisis exploratorio (EDA) de las variables de talento humano.  \n",
    "- Identificar patrones y distribuciones en los datos.  \n",
    "- Preparar el dataset para modelado predictivo (limpieza, codificaci√≥n, escalado).  \n",
    "\n",
    "## üõ†Ô∏è Herramientas a utilizar\n",
    "- **pandas** y **numpy**: manipulaci√≥n de datos.  \n",
    "- **matplotlib** y **seaborn**: visualizaci√≥n exploratoria.  \n",
    "\n",
    "‚û°Ô∏è Al finalizar este notebook, tendr√°s un **dataset limpio y analizado**, listo para ser utilizado en la construcci√≥n de modelos de predicci√≥n de perfiles de talento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adD6qliS_PTt"
   },
   "source": [
    "### ***Conocimiento del problema y de los datos.***\n",
    "\n",
    "\n",
    "La parte m√°s importante del machine learning es comprender los datos con los que estamos trabajando y c√≥mo se relacionan con la tarea que desea realizar. No ser√° efectivo elegir aleatoriamente un algoritmo y arrojarle los datos. Es necesario comprender lo que est√° sucediendo en el dataset antes de comenzar a\n",
    "construir un modelo. Cada algoritmo es diferente en t√©rminos de qu√© tipo de datos y la configuraci√≥n del problema para la que funciona mejor. \n",
    "\n",
    "Mientras se crea una soluci√≥n de machine learning se debe tener en cuenta:\n",
    "\n",
    "- ¬øQu√© pregunta(s) se est√° tratando de responder? ¬øCreo que los datos recopilados pueden responder esa pregunta?\n",
    "\n",
    "- ¬øCu√°l es la mejor manera de formular mis preguntas como un problema de machine learning?\n",
    "\n",
    "- ¬øHe recopilado suficientes datos para representar el problema que quiero resolver?\n",
    "\n",
    "- ¬øQu√© caracter√≠sticas de los datos extraje y permitir√°n las predicciones?\n",
    "\n",
    "- ¬øC√≥mo medir√© el √©xito de mi soluci√≥n?\n",
    "\n",
    "- ¬øC√≥mo interactuar√° la soluci√≥n de machine learning con otras partes de mi investigaci√≥n o producto comercial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de librer√≠as necesarias\n",
    "# \n",
    "# En esta celda instalamos las principales librer√≠as que usaremos a lo largo del notebook:\n",
    "# - pandas: para manipulaci√≥n y an√°lisis de datos.\n",
    "# - numpy: para operaciones num√©ricas y manejo de arreglos.\n",
    "# - matplotlib: para visualizaciones b√°sicas.\n",
    "# - seaborn: para visualizaciones estad√≠sticas m√°s estilizadas.\n",
    "# - scikit-learn: para construir y evaluar modelos de machine learning.\n",
    "#\n",
    "# Esta celda solo necesita ejecutarse una vez (o cuando el entorno no tenga estas librer√≠as instaladas).\n",
    "\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1659667559178,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "rziSdyAnOfur",
    "outputId": "ddd2363b-b046-4aeb-e124-0d9e06cba4d2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# create a simple dataset of people\n",
    "data = {'Name': [\"John\", \"Anna\", \"Peter\", \"Linda\"],'Location' : [\"New York\", \"Paris\", \"Berlin\", \"London\"],\n",
    "        'Age' : [24, 13, 53, 33],}\n",
    "\n",
    "data_pandas = pd.DataFrame(data)\n",
    "display(data_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1659667559179,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "PAcRHoXPOm89",
    "outputId": "d100e10a-6c0f-4763-d265-b0b6036a68cd"
   },
   "outputs": [],
   "source": [
    "# Seleccionamos todos los registros con \"Age\" mayor a 30.\n",
    "display(data_pandas[data_pandas[\"Age\"] > 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 681,
     "status": "ok",
     "timestamp": 1659667559846,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "Wtso7lxrO6sf",
    "outputId": "3de6ab79-2e3f-478c-9e93-d5175173c7ae"
   },
   "outputs": [],
   "source": [
    "# Manipulaci√≥n y an√°lisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualizaci√≥n de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelado predictivo\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jM2YfWz33EiG"
   },
   "source": [
    "## ***Primera aplicaci√≥n: clasificaci√≥n de perfiles de talento***\n",
    "\n",
    "Vamos a abordar una primera aplicaci√≥n de *machine learning* creando nuestro primer modelo.\n",
    "\n",
    "Supongamos que el √°rea de Recursos Humanos de una empresa est√° interesada en **distinguir los perfiles de talento** de sus colaboradores para dise√±ar estrategias de formaci√≥n y retenci√≥n m√°s efectivas.  \n",
    "\n",
    "El √°rea ha recopilado algunas caracter√≠sticas asociadas a cada empleado:  \n",
    "\n",
    "- _A√±os de experiencia._  \n",
    "- _Nivel de formaci√≥n continua._  \n",
    "- _Competencias t√©cnicas._  \n",
    "- _Competencias blandas._  \n",
    "\n",
    "Estos valores han sido previamente medidos y normalizados en una escala num√©rica.\n",
    "\n",
    "Adem√°s, se cuenta con la clasificaci√≥n de cada empleado realizada por expertos en gesti√≥n humana, que identificaron perfiles de talento como:  \n",
    "\n",
    "- _Innovador._  \n",
    "- _Ejecutor._  \n",
    "- _Tradicionalista._    \n",
    "\n",
    "Supongamos que estos son los perfiles m√°s representativos en la organizaci√≥n.\n",
    "\n",
    "***Objetivo:*** Construir un modelo de *machine learning* que pueda aprender de las caracter√≠sticas de los empleados con perfil ya identificado, de modo que podamos **predecir el perfil de talento** de un nuevo colaborador a partir de sus competencias y experiencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üì• Cargar el dataset de Recursos Humanos\n",
    "\n",
    "# Definimos la URL donde se encuentra almacenado el archivo CSV.\n",
    "# En este caso, el dataset est√° publicado en un repositorio de GitHub.\n",
    "url = \"https://raw.githubusercontent.com/LeStark/Cursos/refs/heads/main/Data/iris_human_resources.csv\"\n",
    "\n",
    "# Leemos el archivo CSV y lo cargamos en un DataFrame de pandas.\n",
    "# El par√°metro sep=\",\" indica que el separador de columnas es la coma.\n",
    "df = pd.read_csv(url, sep=\",\")\n",
    "\n",
    "# Inspecci√≥n inicial del dataset\n",
    "\n",
    "# Obtenemos informaci√≥n general del DataFrame:\n",
    "# - n√∫mero de filas y columnas\n",
    "# - nombre y tipo de cada columna\n",
    "# - conteo de valores no nulos\n",
    "# Esto nos da una idea de la calidad y estructura del dataset.\n",
    "df.info()\n",
    "\n",
    "# Mostramos las primeras filas para verificar que los datos se cargaron correctamente.\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1659667559855,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "lgvYO5-S_iTN",
    "outputId": "8102b400-d0ad-42ac-be9e-27d14cf838a8"
   },
   "outputs": [],
   "source": [
    "# Identificar las clases de la variable objetivo (target)\n",
    "\n",
    "# La columna \"Perfil de talento\" es nuestra variable de salida o target,\n",
    "# es decir, la categor√≠a que queremos predecir con el modelo.\n",
    "# Con el m√©todo .unique() obtenemos los valores distintos que existen en esa columna.\n",
    "\n",
    "print(\"Target: {}\".format(df['Perfil de talento'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1659667559858,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "eQvLkLLwBTAg",
    "outputId": "a52ca723-368f-41f3-a225-2e87ab8e0417"
   },
   "outputs": [],
   "source": [
    "# Revisar el tama√±o del dataset\n",
    "\n",
    "# La propiedad .shape de un DataFrame devuelve una tupla con:\n",
    "# - N√∫mero de filas (registros de empleados).\n",
    "# - N√∫mero de columnas (variables o caracter√≠sticas medidas).\n",
    "#\n",
    "# Usamos .format() para mostrar el resultado en un mensaje m√°s claro.\n",
    "\n",
    "print(\"Tama√±o de la data: {}\".format(df.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a50dx4EhTeqd"
   },
   "source": [
    "## An√°lisis exploratorio inicial de los datos\n",
    "\n",
    "Antes de construir nuestro modelo, es importante detenernos a **explorar los datos**.  \n",
    "Esto nos permite responder preguntas como:  \n",
    "\n",
    "- ¬øLa informaci√≥n disponible realmente contiene se√±ales que nos ayuden a predecir el perfil de talento?  \n",
    "- ¬øExisten anomal√≠as o valores inusuales en las mediciones?  \n",
    "- ¬øHay variables que parecen m√°s relevantes que otras?  \n",
    "\n",
    "En el mundo real, los datos de Recursos Humanos suelen presentar **inconsistencias**: registros incompletos, escalas diferentes de medici√≥n o valores inesperados. Por ejemplo, un empleado con ‚Äú0 a√±os de experiencia‚Äù pero clasificado como *Ejecutor* podr√≠a ser un dato err√≥neo o reflejar una situaci√≥n particular.  \n",
    "\n",
    "Una de las mejores formas de iniciar esta exploraci√≥n es **visualizando los datos**.  \n",
    "Con pocas variables (como en nuestro caso: experiencia, formaci√≥n continua, competencias t√©cnicas y blandas), los **scatter plots** o diagramas de dispersi√≥n son una herramienta muy √∫til.  \n",
    "\n",
    "üëâ Ten en cuenta que estos gr√°ficos muestran la relaci√≥n entre pares de variables, pero no capturan todas las interacciones posibles al mismo tiempo. Aun as√≠, son una excelente primera aproximaci√≥n para detectar patrones y tendencias en los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Resumen de m√©tricas descriptivas\n",
    "\n",
    "Una buena pr√°ctica es calcular estad√≠sticas descriptivas que nos permitan entender la distribuci√≥n de cada variable num√©rica.  \n",
    "\n",
    "En este caso, construiremos una tabla con las siguientes m√©tricas:  \n",
    "- **Media** ‚Üí valor promedio.  \n",
    "- **Mediana** ‚Üí valor central de la distribuci√≥n.  \n",
    "- **Moda** ‚Üí valor m√°s frecuente.  \n",
    "- **Desviaci√≥n est√°ndar** ‚Üí mide qu√© tan dispersos est√°n los datos respecto a la media.  \n",
    "- **M√≠nimo y M√°ximo** ‚Üí valores extremos de cada variable.  \n",
    "- **Percentil 25 y 75** ‚Üí delimitan el rango intermedio donde se encuentra el 50% central de los datos.  \n",
    "\n",
    "Estas m√©tricas nos ayudar√°n a detectar patrones, posibles anomal√≠as y la variabilidad de cada caracter√≠stica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir tabla de m√©tricas descriptivas para las variables num√©ricas\n",
    "\n",
    "# Seleccionamos solo columnas num√©ricas\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculamos las principales m√©tricas\n",
    "summary = pd.DataFrame({\n",
    "    \"Media\": numeric_df.mean(),\n",
    "    \"Mediana\": numeric_df.median(),\n",
    "    \"Moda\": numeric_df.mode().iloc[0],\n",
    "    \"Desviaci√≥n est√°ndar\": numeric_df.std(),\n",
    "    \"M√≠nimo\": numeric_df.min(),\n",
    "    \"M√°ximo\": numeric_df.max(),\n",
    "    \"Percentil 25\": numeric_df.quantile(0.25),\n",
    "    \"Percentil 75\": numeric_df.quantile(0.75)\n",
    "})\n",
    "\n",
    "# Mostrar tabla\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploraci√≥n inicial de caracter√≠sticas por perfil de talento\n",
    "\n",
    "Antes de construir modelos de clasificaci√≥n, es importante entender c√≥mo se distribuyen las variables\n",
    "en relaci√≥n con los perfiles de talento.  \n",
    "Dos visualizaciones √∫tiles son:\n",
    "\n",
    "- **Boxplots**: muestran la distribuci√≥n de cada variable (mediana, cuartiles, valores at√≠picos) seg√∫n el perfil.  \n",
    "- **Gr√°ficos de barras**: permiten comparar los valores medios de las caracter√≠sticas entre perfiles.\n",
    "\n",
    "Estas gr√°ficas nos ayudan a responder preguntas como:  \n",
    "- ¬øLos *Tradicionalistas* tienden a tener m√°s a√±os de experiencia que los *Innovadores*?  \n",
    "- ¬øExisten diferencias claras en competencias blandas entre los tres perfiles?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Conteo de empleados por perfil de talento\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x=\"Perfil de talento\", data=df, palette=\"Set2\")\n",
    "\n",
    "plt.title(\"N√∫mero de muestras por perfil de talento\")\n",
    "plt.xlabel(\"Perfil de talento\")\n",
    "plt.ylabel(\"Cantidad de empleados\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots por perfil de talento\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "sns.boxplot(x=\"Perfil de talento\", y=\"A√±os de experiencia\", data=df, ax=axes[0,0])\n",
    "axes[0,0].set_title(\"Distribuci√≥n de A√±os de Experiencia\")\n",
    "\n",
    "sns.boxplot(x=\"Perfil de talento\", y=\"Formaci√≥n continua\", data=df, ax=axes[0,1])\n",
    "axes[0,1].set_title(\"Distribuci√≥n de Formaci√≥n Continua\")\n",
    "\n",
    "sns.boxplot(x=\"Perfil de talento\", y=\"Competencias t√©cnicas\", data=df, ax=axes[1,0])\n",
    "axes[1,0].set_title(\"Distribuci√≥n de Competencias T√©cnicas\")\n",
    "\n",
    "sns.boxplot(x=\"Perfil de talento\", y=\"Competencias blandas\", data=df, ax=axes[1,1])\n",
    "axes[1,1].set_title(\"Distribuci√≥n de Competencias Blandas\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores promedio de cada caracter√≠stica por perfil\n",
    "mean_values = df.groupby(\"Perfil de talento\").mean(numeric_only=True)\n",
    "\n",
    "mean_values.plot(kind=\"bar\", figsize=(10,6))\n",
    "plt.title(\"Promedio de caracter√≠sticas por perfil de talento\")\n",
    "plt.ylabel(\"Valor promedio\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Caracter√≠sticas\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppPT-9aYP5ZV"
   },
   "source": [
    "#### ***An√°lisis avanzado***\n",
    "\n",
    "Construya un [`pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html) o un [`PairGrid`](https://seaborn.pydata.org/generated/seaborn.PairGrid.html) en donde:\n",
    "\n",
    "- La **diagonal principal** muestre un histograma de cada variable num√©rica.  \n",
    "- Los **gr√°ficos fuera de la diagonal** sean *scatter plots* que comparen pares de variables.  \n",
    "- Utilice el par√°metro `hue` con la columna **Perfil de talento**, de manera que cada punto est√© coloreado seg√∫n el perfil (*Innovador, Ejecutor, Tradicionalista*).  \n",
    "\n",
    "Este ejercicio permite identificar si algunos perfiles de talento tienden a agruparse en torno a ciertas caracter√≠sticas (ej. Innovadores con alta formaci√≥n continua o Tradicionalistas con m√°s a√±os de experiencia).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wSOUZVVQvIY"
   },
   "source": [
    "***Respuesta:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "executionInfo": {
     "elapsed": 8785,
     "status": "ok",
     "timestamp": 1659667568608,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "8agJONssMpcL",
    "outputId": "b4111b88-3a01-4d45-c75f-054b58a99185"
   },
   "outputs": [],
   "source": [
    "# üìä Versi√≥n avanzada con PairGrid\n",
    "\n",
    "g = sns.PairGrid(df, hue=\"Perfil de talento\")\n",
    "g.map_diag(sns.histplot, kde=False)  # Histogramas en la diagonal\n",
    "g.map_offdiag(sns.scatterplot, alpha=0.7)  # Scatter plots fuera de la diagonal\n",
    "g.add_legend()  # Agregar leyenda\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wniWm15HUtGo"
   },
   "source": [
    "De las gr√°ficas podemos observar que los tres perfiles de talento (**Innovador, Ejecutor y Tradicionalista**) tienden a separarse en funci√≥n de las variables analizadas.  \n",
    "\n",
    "Por ejemplo:  \n",
    "- Los **Innovadores** aparecen concentrados en niveles bajos de a√±os de experiencia, competencias t√©cnicas y blandas.  \n",
    "- Los **Ejecutores** muestran valores intermedios tanto en competencias t√©cnicas como en blandas.  \n",
    "- Los **Tradicionalistas** tienden a ubicarse en los rangos m√°s altos de a√±os de experiencia y competencias.  \n",
    "\n",
    "Esto sugiere que un modelo de aprendizaje autom√°tico podr√° **aprender patrones claros** en los datos y distinguir entre los perfiles de talento a partir de las variables disponibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaci√≥n de los datos\n",
    "\n",
    "Antes de entrenar un modelo de *machine learning*, es necesario preparar los datos.  \n",
    "En este caso, realizaremos dos pasos fundamentales:\n",
    "\n",
    "### 1. Codificaci√≥n de la variable objetivo (target)\n",
    "\n",
    "La columna **Perfil de talento** contiene etiquetas de texto (*Innovador, Ejecutor, Tradicionalista*).  \n",
    "Los algoritmos no pueden trabajar directamente con texto, por lo que debemos **convertir estas categor√≠as en valores num√©ricos**.  \n",
    "Para esto usamos `LabelEncoder`, que asigna un n√∫mero entero a cada clase.  \n",
    "\n",
    "Ejemplo:  \n",
    "- Innovador ‚Üí 0  \n",
    "- Ejecutor ‚Üí 1  \n",
    "- Tradicionalista ‚Üí 2  \n",
    "\n",
    "*(El orden depende de c√≥mo se encuentren en el dataset.)*\n",
    "\n",
    "### 2. Normalizaci√≥n de las variables num√©ricas\n",
    "\n",
    "Las variables de entrada (**A√±os de experiencia, Formaci√≥n continua, Competencias t√©cnicas, Competencias blandas**) tienen escalas diferentes.  \n",
    "Si no las normalizamos, una variable con n√∫meros grandes podr√≠a influir m√°s en el modelo que otra con n√∫meros peque√±os.  \n",
    "\n",
    "Usaremos `StandardScaler`, que transforma cada variable para que:  \n",
    "- Tenga media = 0.  \n",
    "- Tenga desviaci√≥n est√°ndar = 1.  \n",
    "\n",
    "De esta forma, todas las caracter√≠sticas quedan en la **misma escala** y el modelo puede tratarlas de manera justa.\n",
    "\n",
    "Con estos dos pasos tendremos un **dataset listo para la clasificaci√≥n**, donde:  \n",
    "- El target est√° representado en n√∫meros.  \n",
    "- Las variables de entrada est√°n estandarizadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaci√≥n de los datos para modelado\n",
    "\n",
    "# 1. Separar features (X) y target (y)\n",
    "X = df.drop(\"Perfil de talento\", axis=1)   # Variables independientes\n",
    "y = df[\"Perfil de talento\"]               # Variable objetivo\n",
    "\n",
    "# 2. Codificaci√≥n de la variable target (Innovador, Ejecutor, Tradicionalista ‚Üí 0,1,2)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"Clases originales:\", label_encoder.classes_)\n",
    "\n",
    "# Seleccionar 10 √≠ndices aleatorios sin repetici√≥n\n",
    "indices = np.random.choice(len(y_encoded), size=10, replace=False)\n",
    "\n",
    "# Mostrar las clases codificadas de esos 10 empleados\n",
    "print(\"Clases codificadas (10 aleatorias):\", y_encoded[indices])\n",
    "\n",
    "# 3. Normalizaci√≥n/Estandarizaci√≥n de las features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Verificaci√≥n de la transformaci√≥n\n",
    "print(\"\\nPrimeras 5 filas de las variables normalizadas:\")\n",
    "print(X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFi-u04ddvMO"
   },
   "source": [
    "### ***Conjuntos de datos Training y Test***\n",
    "\n",
    "Nuestro objetivo es construir un modelo de *machine learning* que pueda ***predecir*** el perfil de talento de un nuevo colaborador a partir de sus caracter√≠sticas (**a√±os de experiencia, formaci√≥n continua, competencias t√©cnicas y blandas**).  \n",
    "\n",
    "Para lograrlo, necesitamos entrenar un modelo y, adem√°s, comprobar si realmente funciona de manera confiable.  \n",
    "\n",
    "No podemos evaluar el modelo con los mismos datos que usamos para entrenarlo.  \n",
    "La raz√≥n es que el modelo podr√≠a ‚Äúmemorizar‚Äù los ejemplos que ya conoce y predecir siempre correctamente para esos casos, pero eso **no garantiza** que funcione igual de bien con datos nuevos.  \n",
    "\n",
    "En otras palabras, queremos que el modelo no solo aprenda los datos actuales, sino que tambi√©n **se generalice** a futuros colaboradores que no ha visto antes.  \n",
    "\n",
    "La forma de resolver este problema es **dividir nuestro dataset en dos partes**:  \n",
    "1. **Training data (datos de entrenamiento):** se usan para construir el modelo.  \n",
    "2. **Test data (datos de prueba):** se usan para evaluar qu√© tan bien predice el modelo sobre ejemplos que nunca ha visto.  \n",
    "\n",
    "En `scikit-learn` podemos hacer esta divisi√≥n con la funci√≥n `train_test_split`.  \n",
    "De manera est√°ndar, se toma aproximadamente el **75% de los datos para entrenamiento** y el **25% para prueba**.  \n",
    "Esta proporci√≥n suele ser una buena pr√°ctica porque deja suficiente informaci√≥n para entrenar el modelo, pero tambi√©n una muestra representativa para evaluarlo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Dividir el dataset en Training y Test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = variables predictoras (todas menos 'Perfil de talento')\n",
    "# y_encoded = variable objetivo ya codificada (Innovador=0, Ejecutor=1, Tradicionalista=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,        # Datos normalizados (features)\n",
    "    y_encoded,       # Target codificado\n",
    "    test_size=0.25,  # 25% para prueba, 75% para entrenamiento\n",
    "    random_state=42, # Semilla para reproducibilidad\n",
    "    stratify=y_encoded, # Garantiza que las clases queden balanceadas en train y test\n",
    "    shuffle=True      # Mezcla los datos antes de dividir\n",
    ")\n",
    "\n",
    "# Verificamos el tama√±o de cada conjunto\n",
    "print(\"Tama√±o de X_train:\", X_train.shape)\n",
    "print(\"Tama√±o de X_test:\", X_test.shape)\n",
    "print(\"Tama√±o de y_train:\", y_train.shape)\n",
    "print(\"Tama√±o de y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKjCUEONU8bG"
   },
   "source": [
    "### ***Construcci√≥n de nuestro primer modelo: [`k-Nearest Neighbors`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)***\n",
    "\n",
    "El modelo **k-Nearest Neighbors (KNN)** es uno de los algoritmos de clasificaci√≥n m√°s sencillos de entender e implementar.  \n",
    "\n",
    "La idea central es que **para clasificar un nuevo registro de datos (por ejemplo, un colaborador cuyo perfil de talento a√∫n no conocemos), el algoritmo busca en el conjunto de entrenamiento los registros m√°s similares** y asigna la clase predominante entre ellos.  \n",
    "\n",
    "- Si usamos **k = 1**, el modelo buscar√° √∫nicamente el vecino m√°s cercano en el conjunto de entrenamiento y le asignar√° su mismo perfil de talento (*Innovador, Ejecutor o Tradicionalista*).  \n",
    "- Si usamos un valor mayor de **k** (por ejemplo, 3 o 5), el algoritmo considerar√° a los 3 o 5 vecinos m√°s cercanos, y clasificar√° el nuevo registro seg√∫n la **clase mayoritaria** en ese grupo.  \n",
    "\n",
    "De esta forma, KNN se basa completamente en la **proximidad**: los individuos que se parecen entre s√≠ (seg√∫n sus caracter√≠sticas: experiencia, formaci√≥n, competencias) tienden a compartir la misma etiqueta de perfil.  \n",
    "\n",
    " En esta primera implementaci√≥n, comenzaremos usando **k = 3** para ilustrar el funcionamiento b√°sico del modelo. M√°s adelante exploraremos c√≥mo elegir el valor de *k* de manera m√°s adecuada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1659667568619,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "7cOJ5wR2Xbnw"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vvAWZgXXoj4"
   },
   "source": [
    "El objeto `knn` encapsula el algoritmo que se usar√° para construir el modelo a partir de los datos en train, as√≠ como el algoritmo para hacer predicciones sobre nuevos puntos de datos. Tambi√©n contienen la informaci√≥n que el algoritmo ha extra√≠do de los datos de entrenamiento. En el caso de KNeighborsClassifier, solo almacenar√° el conjunto de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1659667568620,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "Q-cFySz1YoMl",
    "outputId": "563bebf1-8ca7-43de-fde6-066eca422d6c"
   },
   "outputs": [],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js9coC2bZuYE"
   },
   "source": [
    "Lo anterior nos muestra qu√© par√°metros\n",
    "se usar√°n para crear el modelo. Casi todos ellos son los valores predeterminados, note que tenemos `n_neighbors=1`, que es el par√°metro que pasamos. La mayor√≠a de los modelos en `scikit-learn` tiene muchos par√°metros, pero la mayor√≠a de ellos son optimizaciones de velocidad o para casos de uso muy especiales. Por ahora, no nos preocupamos por el otros par√°metros mostrados. Recuerde que m√°s adelante cubriremos toda la tem√°tica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IR7h8aza4Wc"
   },
   "source": [
    "Para construir el modelo en el conjunto train, llamamos al m√©todo `fit()` que es el ajuste del objeto `knn`, que toma como argumentos el NumPy array `X_train` que contiene la data train y el NumPy array en `y_train` de las etiquetas de train correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1659667568622,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "HnAP1wHKYRrH",
    "outputId": "f8ab39c0-329a-46e0-ca5b-1fba08bd3454"
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdHjt4Pwfc19"
   },
   "source": [
    "### ***Haciendo predicciones***\n",
    "\n",
    "Una vez entrenado nuestro modelo, podemos usarlo para hacer predicciones sobre **nuevos colaboradores** cuyo perfil de talento a√∫n no conocemos.  \n",
    "\n",
    "Supongamos que llega un nuevo empleado con las siguientes caracter√≠sticas:\n",
    "\n",
    "- **A√±os de experiencia:** 4  \n",
    "- **Formaci√≥n continua:** 3  \n",
    "- **Competencias t√©cnicas:** 2  \n",
    "- **Competencias blandas:** 4  \n",
    "\n",
    "üëâ ¬øA qu√© perfil de talento pertenecer√° este colaborador? (*Innovador, Ejecutor o Tradicionalista*)  \n",
    "\n",
    "Para que el modelo pueda procesar estos datos, debemos organizarlos en un **array de NumPy** con la forma adecuada:  \n",
    "- N√∫mero de muestras = 1 (porque es un solo empleado nuevo).  \n",
    "- N√∫mero de caracter√≠sticas = 4 (a√±os de experiencia, formaci√≥n continua, competencias t√©cnicas y blandas).  \n",
    "\n",
    "De esta manera, el modelo podr√° recibir la informaci√≥n en el mismo formato con el que fue entrenado y generar la predicci√≥n correspondiente.\n",
    "\n",
    "Recordemos las estadisticas desxcriptivas de los datos con que fue entrenado: \n",
    "\n",
    "## Tabla de m√©tricas descriptivas\n",
    "\n",
    "| Caracter√≠stica           | Media    | Mediana | Moda | Desviaci√≥n est√°ndar | M√≠nimo | M√°ximo | Percentil 25 | Percentil 75 |\n",
    "|---------------------------|----------|---------|------|----------------------|--------|--------|--------------|--------------|\n",
    "| **A√±os de experiencia**   | 5.843333 | 5.80    | 5.0  | 0.828066             | 4.3    | 7.9    | 5.1          | 6.4          |\n",
    "| **Formaci√≥n continua**    | 3.057333 | 3.00    | 3.0  | 0.435866             | 2.0    | 4.4    | 2.8          | 3.3          |\n",
    "| **Competencias t√©cnicas** | 3.758000 | 4.35    | 1.4  | 1.765298             | 1.0    | 6.9    | 1.6          | 5.1          |\n",
    "| **Competencias blandas**  | 1.199333 | 1.30    | 0.2  | 0.762238             | 0.1    | 2.5    | 0.3          | 1.8          |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1659667568623,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "T48t-roNbRiK",
    "outputId": "f6b03637-5cef-46d1-8c12-4baad2bc8ea6"
   },
   "outputs": [],
   "source": [
    "# Crear un nuevo registro para hacer una predicci√≥n\n",
    "\n",
    "# Definimos un colaborador ficticio con sus caracter√≠sticas:\n",
    "# - A√±os de experiencia = 5\n",
    "# - Formaci√≥n continua = 2.9\n",
    "# - Competencias t√©cnicas = 1\n",
    "# - Competencias blandas = 0.2\n",
    "#\n",
    "# Importante: los valores deben estar en una lista dentro de otra lista [[...]]\n",
    "# porque el modelo espera un array bidimensional:\n",
    "#   - 1 fila  -> una sola muestra (un empleado nuevo)\n",
    "#   - 4 columnas -> cuatro caracter√≠sticas\n",
    "\n",
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "\n",
    "# Verificamos la forma del array: (n_muestras, n_features)\n",
    "print(\"X_new.shape: {}\".format(X_new.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1659667569027,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "YkebP_TkbUvD",
    "outputId": "64ccfa5f-d7f3-4a2a-cf62-1a8f4fb78fab"
   },
   "outputs": [],
   "source": [
    "# Predicci√≥n con el modelo KNN asegurando la normalizaci√≥n del nuevo dato\n",
    "\n",
    "# 1. Normalizamos el nuevo registro con el mismo scaler usado en el entrenamiento\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# 2. Hacemos la predicci√≥n con el modelo entrenado\n",
    "prediction = knn.predict(X_new_scaled)\n",
    "\n",
    "# 3. Recuperamos el nombre de la etiqueta original usando el LabelEncoder\n",
    "predicted_label = label_encoder.inverse_transform(prediction)\n",
    "\n",
    "print(\"Predicci√≥n (codificada):\", prediction)\n",
    "print(\"Perfil de talento predicho:\", predicted_label[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsK55kMcj51i"
   },
   "source": [
    "Nuestro modelo predice que este nuevo colaborador pertenece a la **clase 1**, lo que significa que su perfil de talento es **Ejecutor**.  \n",
    "\n",
    "Ahora bien, surge una pregunta clave:  \n",
    "**¬øC√≥mo sabemos si podemos confiar en nuestro modelo?**  \n",
    "\n",
    "En este caso, no conocemos el perfil real de este colaborador (ese es precisamente el objetivo de construir el modelo: predecirlo).  \n",
    "Por eso, para evaluar la confiabilidad del modelo debemos probarlo con datos donde **s√≠ conocemos la etiqueta real**, es decir, con el conjunto de prueba (*test set*).  \n",
    "\n",
    "De esta manera podemos comparar las predicciones del modelo con las etiquetas verdaderas y medir qu√© tan bien est√° funcionando.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq3zdmwHkVa5"
   },
   "source": [
    "### ***Evaluaci√≥n del modelo***\n",
    "\n",
    "¬øRecuerda que tenemos un conjunto de **test**?  \n",
    "Es aqu√≠ donde entra en juego.  \n",
    "\n",
    "Sabemos que estos datos **no se usaron para construir el modelo**, pero s√≠ conocemos el perfil de talento correcto para cada colaborador en este conjunto.  \n",
    "\n",
    "Por lo tanto, podemos hacer una **predicci√≥n para cada empleado del test set** y compararla contra su etiqueta real (el perfil de talento conocido: *Innovador, Ejecutor o Tradicionalista*).  \n",
    "\n",
    "De esta forma, podremos medir qu√© tan bien funciona el modelo.  \n",
    "Una de las m√©tricas m√°s utilizadas es la **precisi√≥n (accuracy)**, que indica la proporci√≥n de colaboradores para los que el modelo hizo una predicci√≥n correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1659667569027,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "ITMo94Znk9ra",
    "outputId": "38dcd23e-57da-4d6c-bd07-0869164814b2"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Predicciones en el conjunto test:\\n\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7tzognal7d2"
   },
   "source": [
    "Podemos usar el m√©todo `score()` del objeto knn, que calcular√° la puntuaci√≥n con exactitud:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1659667569029,
     "user": {
      "displayName": "Luis Andres Campos Maldonado",
      "userId": "15478348060554261231"
     },
     "user_tz": 300
    },
    "id": "pnk-z7cxmMWP",
    "outputId": "e296cf35-4865-43fe-e643-19ba394c621d"
   },
   "outputs": [],
   "source": [
    "print(\"Score en el conjunto test: {:.2f}\".format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXCaVCr6mZ8n"
   },
   "source": [
    "Para este modelo, el `accuracy` en el conjunto test es de aproximadamente 0,97, lo que significa que hicimos un buen trabajo en la predicci√≥n para el 97% de los iris en el conjunto test. Bajo algunos supuestos matem√°ticos, esto significa que podemos esperar que nuestro modelo sea correcto el 97% del tiempo para nuevos\n",
    "iris. Este alto nivel de precisi√≥n significa que nuestro\n",
    "el modelo puede ser lo suficientemente confiable como para usarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHO9kGKAnENG"
   },
   "source": [
    "## ***Conclusiones y comentarios***\n",
    "\n",
    "En este ejercicio realizamos una breve introducci√≥n al *machine learning* aplicado a **Recursos Humanos**, explorando c√≥mo estas t√©cnicas permiten apoyar la toma de decisiones estrat√©gicas.  \n",
    "\n",
    "Primero discutimos la diferencia entre **aprendizaje supervisado y no supervisado**, y revisamos las herramientas b√°sicas que utilizamos en el curso.  \n",
    "\n",
    "Luego abordamos el reto de construir un modelo capaz de **predecir el perfil de talento de un colaborador** a partir de sus caracter√≠sticas principales: a√±os de experiencia, formaci√≥n continua, competencias t√©cnicas y competencias blandas.  \n",
    "\n",
    "En este contexto trabajamos con un problema de **clasificaci√≥n multiclase**, ya que el perfil de un empleado puede ser:  \n",
    "- *Innovador*  \n",
    "- *Ejecutor*  \n",
    "- *Tradicionalista*  \n",
    "\n",
    "Dividimos nuestro dataset en **conjunto de entrenamiento (train)** y **conjunto de prueba (test)**. Con los datos de entrenamiento construimos el modelo y con los de prueba evaluamos su desempe√±o, es decir, qu√© tan bien se generaliza a colaboradores que nunca hab√≠a visto.  \n",
    "\n",
    "El algoritmo seleccionado fue **k-Nearest Neighbors (KNN)**, el cual clasifica un nuevo colaborador considerando los perfiles de sus vecinos m√°s cercanos en el conjunto de entrenamiento. Para esto:  \n",
    "- Instanciamos la clase del modelo.  \n",
    "- Ajustamos el modelo con `fit()` usando `X_train` y `y_train`.  \n",
    "- Evaluamos su desempe√±o con `score()` sobre el conjunto `test`.  \n",
    "\n",
    "El resultado obtenido fue una **precisi√≥n (accuracy) de aproximadamente 95%**, lo que significa que el modelo clasific√≥ correctamente el perfil de talento en 95 de cada 100 casos del conjunto de prueba.  \n",
    "\n",
    "Este resultado sugiere que el modelo tiene un **alto poder predictivo**, aunque siempre ser√° importante complementarlo con validaciones adicionales y consideraciones √©ticas antes de usarlo en decisiones reales de gesti√≥n humana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "def predecir_perfil(a√±os_experiencia, formacion_continua, competencias_tecnicas, competencias_blandas):\n",
    "    # Construimos el array con los valores ingresados\n",
    "    X_user = np.array([[a√±os_experiencia, formacion_continua, competencias_tecnicas, competencias_blandas]])\n",
    "    X_user_scaled = scaler.transform(X_user)\n",
    "\n",
    "    # Predicci√≥n\n",
    "    prediction = knn.predict(X_user_scaled)\n",
    "    predicted_label = label_encoder.inverse_transform(prediction)\n",
    "    \n",
    "    print(\"üìä Perfil de talento predicho:\", predicted_label[0])\n",
    "\n",
    "# Sliders interactivos\n",
    "interact(\n",
    "    predecir_perfil,\n",
    "    a√±os_experiencia=widgets.FloatSlider(min=0, max=10, step=0.1, value=3),\n",
    "    formacion_continua=widgets.FloatSlider(min=0, max=5, step=0.1, value=2.5),\n",
    "    competencias_tecnicas=widgets.FloatSlider(min=0, max=10, step=0.1, value=5),\n",
    "    competencias_blandas=widgets.FloatSlider(min=0, max=5, step=0.1, value=2)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPScUkWAvroLOPkczkufGV5",
   "name": "Lectura_1_Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
