{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa34d520",
   "metadata": {},
   "source": [
    "#  IA para Redes de Suministro \n",
    "\n",
    "üë§ **Autor:** John Leonardo Vargas Mesa  \n",
    "üîó [LinkedIn](https://www.linkedin.com/in/leonardovargas/) | [GitHub](https://github.com/LeStark)  \n",
    "\n",
    "## üìÇ Repositorio en GitHub  \n",
    "- üìì **Notebooks:** [Acceder aqu√≠](https://github.com/LeStark/Cursos/tree/main/An%C3%A1lisis%20predictivo%20para%20toma%20de%20decisiones%20RRHH)  \n",
    "- üìë **Data sets:** [Acceder aqu√≠](https://github.com/LeStark/Cursos/tree/main/Data/RRHH)  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a34d53",
   "metadata": {},
   "source": [
    "# üìò Notebook 1 ‚Äì Introducci√≥n al Machine Learning en Cadenas de Suministro\n",
    "\n",
    "En este notebook trabajaremos con datasets adaptados que representan distintos procesos dentro de una cadena de suministro: demanda de productos, inventarios y entregas.  \n",
    "\n",
    "Este ser√° nuestro punto de partida para aprender a **explorar, preparar y modelar datos** con el objetivo de apoyar la toma de decisiones log√≠sticas mediante Machine Learning.\n",
    "\n",
    "### üìÇ Estructura del Dataset\n",
    "\n",
    "El dataset contiene informaci√≥n simulada de operaciones log√≠sticas, con variables como:\n",
    "\n",
    "- **D√≠a de la semana**: momento del ciclo semanal en el que se registra la demanda.  \n",
    "- **Promoci√≥n activa**: indicador binario sobre campa√±as de descuento.  \n",
    "- **Temperatura**: variable clim√°tica que puede afectar el consumo.  \n",
    "- **Ventas pasadas**: hist√≥rico inmediato de la cantidad vendida.  \n",
    "- **Demanda**: variable objetivo (n√∫mero de unidades a predecir).  \n",
    "\n",
    "En otros casos de clasificaci√≥n, se incluyen variables como:  \n",
    "- **Distancia de entrega**: kil√≥metros entre bodega y cliente.  \n",
    "- **Condiciones clim√°ticas**: lluvia, nieve, soleado.  \n",
    "- **Tr√°fico**: nivel de congesti√≥n reportado.  \n",
    "- **Entrega tard√≠a**: variable objetivo (s√≠/no).  \n",
    "\n",
    "### üéØ Objetivos del Notebook\n",
    "- Realizar un **an√°lisis exploratorio (EDA)** de las variables relacionadas con la log√≠stica y la demanda.  \n",
    "- Entrenar modelos de **regresi√≥n** para la predicci√≥n de demanda.  \n",
    "- Entrenar modelos de **clasificaci√≥n** para predecir entregas tard√≠as.  \n",
    "- Visualizar m√©tricas de desempe√±o y discutir aplicaciones en la vida real.  \n",
    "\n",
    "### üõ†Ô∏è Herramientas a utilizar\n",
    "- **pandas** y **numpy**: manipulaci√≥n de datos.  \n",
    "- **matplotlib** y **seaborn**: visualizaci√≥n exploratoria.  \n",
    "- **scikit-learn**: construcci√≥n de modelos de regresi√≥n y clasificaci√≥n.  \n",
    "\n",
    "Al finalizar este notebook, contar√°s con un dataset preparado y modelos b√°sicos entrenados, lo que te permitir√° comprender c√≥mo aplicar Machine Learning en problemas reales de cadenas de suministro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6a980",
   "metadata": {},
   "source": [
    "## Diccionario de Variables ‚Äì Evaluaci√≥n de Proveedores\n",
    "\n",
    "- **Tiempo_entrega_dias**  \n",
    "  N√∫mero promedio de d√≠as que tarda el proveedor en completar una entrega.  \n",
    "  *Un menor valor indica mayor eficiencia log√≠stica.*  \n",
    "\n",
    "- **Confiabilidad_entregas**  \n",
    "  Medida de la consistencia en los despachos a tiempo y sin errores.  \n",
    "  *Un valor alto refleja proveedores m√°s confiables y estables.*  \n",
    "\n",
    "- **Costos_de_transacci√≥n**  \n",
    "  Costos asociados a la relaci√≥n con el proveedor, incluyendo tr√°mites administrativos, gesti√≥n de √≥rdenes y coordinaci√≥n log√≠stica.  \n",
    "  *Un menor costo significa relaciones m√°s √°giles y econ√≥micas.*  \n",
    "\n",
    "- **Defectos_por_mill√≥n**  \n",
    "  Indicador de calidad basado en el n√∫mero de defectos detectados por cada mill√≥n de unidades entregadas.  \n",
    "  *Un valor bajo se√±ala alta calidad en los productos o servicios suministrados.*  \n",
    "\n",
    "- **categoria_proveedor**  \n",
    "  Clasificaci√≥n del proveedor seg√∫n su rol estrat√©gico dentro de la cadena:  \n",
    "  - **Proveedor Estrat√©gico**: Alta prioridad, fundamental para la operaci√≥n.  \n",
    "  - **Proveedor Regular**: Desempe√±o aceptable, apoyo frecuente en la operaci√≥n.  \n",
    "  - **Proveedor Ocasional**: Uso espor√°dico, bajo impacto estrat√©gico.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84463ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as principales para el proyecto\n",
    "\n",
    "# Manipulaci√≥n y an√°lisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualizaci√≥n de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilidades matem√°ticas\n",
    "import math\n",
    "\n",
    "# Manejo de advertencias (para ocultar mensajes innecesarios)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Preprocesamiento de datos\n",
    "from sklearn.preprocessing import LabelEncoder    # Codificaci√≥n de variables categ√≥ricas\n",
    "from sklearn.preprocessing import StandardScaler  # Estandarizaci√≥n de variables num√©ricas\n",
    "\n",
    "# Divisi√≥n de datos en entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelado con K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Evaluaci√≥n de modelos\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,          # Matriz de confusi√≥n\n",
    "    ConfusionMatrixDisplay,    # Visualizaci√≥n de la matriz de confusi√≥n\n",
    "    classification_report,     # M√©tricas de precisi√≥n, recall y F1\n",
    "    accuracy_score             # Exactitud global\n",
    ")\n",
    "\n",
    "# Guardado y carga de modelos entrenados\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df26534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Carga del Dataset de Evaluaci√≥n de Proveedores\n",
    "# ------------------------------------------------\n",
    "# En esta celda cargamos un dataset adaptado del famoso Iris,\n",
    "# pero reinterpretado en el contexto de cadenas de suministro.\n",
    "#\n",
    "# El archivo est√° almacenado en un repositorio de GitHub y lo\n",
    "# leemos directamente con pandas usando pd.read_csv().\n",
    "# Luego mostramos las primeras filas para confirmar que se carg√≥ bien\n",
    "# y entender la estructura de las variables.\n",
    "\n",
    "#TODO: Definir la URL por la del dataset de evaluaci√≥n de proveedores y cargarla en un DataFrame\n",
    "\n",
    "#Mostrar la informaci√≥n del dataset\n",
    "data.info()\n",
    "\n",
    "# Mostrar las primeras 5 filas del dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b343b",
   "metadata": {},
   "source": [
    "## An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "El **An√°lisis Exploratorio de Datos (EDA, por sus siglas en ingl√©s)** es una etapa fundamental antes de aplicar cualquier modelo de Machine Learning.  \n",
    "Su objetivo es **comprender la estructura de los datos, identificar patrones y detectar posibles problemas** como valores at√≠picos, distribuciones sesgadas o correlaciones entre variables.  \n",
    "\n",
    "En este notebook, el EDA se centra en las siguientes tareas:\n",
    "\n",
    "### 1. Revisi√≥n inicial del dataset\n",
    "- Verificamos el n√∫mero de registros y variables.  \n",
    "- Inspeccionamos los primeros registros con `head()` para asegurarnos de que los datos se cargaron correctamente.  \n",
    "- Revisamos los tipos de datos (num√©ricos, categ√≥ricos) y posibles valores faltantes.\n",
    "\n",
    "### 2. Distribuci√≥n de las variables num√©ricas\n",
    "- Mediante histogramas, KDE (densidad) y boxplots observamos c√≥mo se distribuyen variables como:\n",
    "  - **Tiempo_entrega_dias**  \n",
    "  - **Confiabilidad_entregas**  \n",
    "  - **Costos_de_transacci√≥n**  \n",
    "  - **Defectos_por_mill√≥n**  \n",
    "- Esto nos permite detectar valores extremos y diferencias entre categor√≠as de proveedores.\n",
    "\n",
    "### 3. An√°lisis de la variable categ√≥rica\n",
    "- Analizamos la proporci√≥n de cada clase de `categoria_proveedor` (*Estrat√©gico, Regular, Ocasional*).  \n",
    "- Esta informaci√≥n es clave para identificar si el dataset est√° **balanceado** o si habr√° que aplicar t√©cnicas de balanceo antes del modelado.\n",
    "\n",
    "### 4. Relaciones entre variables\n",
    "- Utilizamos gr√°ficos de dispersi√≥n y pairplots para observar c√≥mo se agrupan los proveedores en el espacio de las variables.  \n",
    "- Calculamos correlaciones entre variables num√©ricas para identificar redundancias o relaciones fuertes que influyan en los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17005bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99265806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de estilo\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Variables num√©ricas\n",
    "variables = data.columns.drop(\"categoria_proveedor\").tolist()\n",
    "\n",
    "# Crear grid de 2x2\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Iterar sobre las variables y ejes\n",
    "for var, ax in zip(variables, axes.flatten()):\n",
    "    sns.boxplot(data=data, x=\"categoria_proveedor\", y=var, ax=ax, palette=\"Set2\")\n",
    "    ax.set_title(f\"{var} vs Categoria de Proveedor\", fontsize=12)\n",
    "    ax.set_xlabel(\"Categor√≠a de Proveedor\")\n",
    "    ax.set_ylabel(var)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6cbccf",
   "metadata": {},
   "source": [
    "### An√°lisis de Boxplots ‚Äì Variables vs Categor√≠a de Proveedor\n",
    "\n",
    "Los boxplots permiten comparar la distribuci√≥n de cada variable de evaluaci√≥n de proveedores seg√∫n la categor√≠a asignada (*Estrat√©gico, Regular u Ocasional*).  \n",
    "\n",
    "#### Tiempo_entrega_dias\n",
    "- **Proveedores Estrat√©gicos** presentan tiempos de entrega m√°s bajos y consistentes (mediana cercana a 5 d√≠as).  \n",
    "- **Proveedores Ocasionales** son los m√°s lentos, con tiempos entre 6 y 8 d√≠as.  \n",
    "- Esto refleja que la eficiencia log√≠stica es un diferenciador claro para la categor√≠a estrat√©gica.  \n",
    "\n",
    "#### Confiabilidad_entregas\n",
    "- Los **Estrat√©gicos** tienen mayor confiabilidad, con una mediana superior a 3.2.  \n",
    "- Los **Regulares** muestran mayor dispersi√≥n y menor nivel de cumplimiento.  \n",
    "- Los **Ocasionales** se ubican en un punto intermedio, aunque con valores menos estables.  \n",
    "\n",
    "#### Costos_de_transacci√≥n\n",
    "- Los **Estrat√©gicos** destacan por tener los costos m√°s bajos (mediana cercana a 1.5).  \n",
    "- Los **Regulares** duplican estos costos, y los **Ocasionales** los triplican.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f98a69",
   "metadata": {},
   "source": [
    "### Uso del Pair Plot para An√°lisis Exploratorio\n",
    "\n",
    "El **pair plot** es una herramienta gr√°fica que nos permite visualizar, en una sola figura, la relaci√≥n entre todas las variables num√©ricas de un dataset.  \n",
    "\n",
    "En este caso, lo utilizamos para analizar c√≥mo se relacionan las variables de evaluaci√≥n de proveedores con la **categor√≠a de proveedor** (*Estrat√©gico, Regular u Ocasional*).  \n",
    "\n",
    "- **En la diagonal**: se muestran las distribuciones de cada variable mediante curvas de densidad (**KDE**). Estas curvas nos permiten observar si los proveedores se agrupan de manera distinta en cada variable individual.  \n",
    "- **Fuera de la diagonal**: aparecen diagramas de dispersi√≥n entre pares de variables. Al incluir el par√°metro `hue=\"categoria_proveedor\"`, cada punto se colorea seg√∫n la categor√≠a, lo que facilita identificar separaciones o solapamientos entre grupos.  \n",
    "\n",
    " Gracias a este gr√°fico, podemos responder preguntas como:  \n",
    "- ¬øQu√© variables separan con mayor claridad a los proveedores estrat√©gicos de los dem√°s?  \n",
    "- ¬øExisten combinaciones de variables que permitan distinguir mejor a proveedores regulares de ocasionales?  \n",
    "- ¬øHay superposici√≥n significativa entre categor√≠as en ciertos atributos?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7548d3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pairplot con densidades KDE en la diagonal\n",
    "sns.pairplot(\n",
    "    data, \n",
    "    vars=[\"Tiempo_entrega_dias\", \"Confiabilidad_entregas\", \n",
    "          \"Costos_de_transacci√≥n\", \"Defectos_por_mill√≥n\"],\n",
    "    hue=\"categoria_proveedor\", \n",
    "    diag_kind=\"kde\", \n",
    "    palette=\"Set2\",\n",
    "    #corner=True\n",
    ")\n",
    "\n",
    "plt.suptitle(\"Relaci√≥n entre variables y Categor√≠a de Proveedor\", y=1.02, fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25bffa9",
   "metadata": {},
   "source": [
    "#### Observaciones clave\n",
    "\n",
    "1. **Separaci√≥n clara de Proveedores Estrat√©gicos**\n",
    "   - Los proveedores estrat√©gicos (verde) se distinguen con facilidad en casi todas las variables.\n",
    "   - Tienen tiempos de entrega m√°s bajos, menores costos de transacci√≥n y defectos casi nulos.\n",
    "   - Esto genera un cl√∫ster compacto y separado en las gr√°ficas de dispersi√≥n.\n",
    "\n",
    "2. **Superposici√≥n entre Proveedores Regulares y Ocasionales**\n",
    "   - Los proveedores regulares (naranja) y ocasionales (azul) muestran un solapamiento considerable en las variables.\n",
    "   - Sin embargo, los ocasionales tienden a concentrarse en los valores m√°s altos de costos de transacci√≥n, defectos por mill√≥n y tiempo de entrega.\n",
    "\n",
    "3. **Relaciones entre variables**\n",
    "   - Existe una **correlaci√≥n positiva** marcada entre:\n",
    "     - *Costos_de_transacci√≥n* y *Defectos_por_mill√≥n*: a mayor costo, tambi√©n se observan m√°s defectos.\n",
    "     - *Tiempo_entrega_dias* y *Costos_de_transacci√≥n*: proveedores con entregas m√°s lentas tambi√©n generan mayores costos.\n",
    "   - La variable *Confiabilidad_entregas* ayuda a separar estrat√©gicos de los dem√°s, pero menos a regulares de ocasionales.\n",
    "\n",
    "4. **Distribuciones univariadas (KDE en la diagonal)**\n",
    "   - Las curvas de densidad confirman que:\n",
    "     - Los **estrat√©gicos** se concentran en valores bajos en todas las m√©tricas de costo, tiempo y defectos.\n",
    "     - Los **ocasionales** presentan distribuciones desplazadas hacia valores altos, especialmente en *Defectos_por_mill√≥n*.\n",
    "     - Los **regulares** se ubican en un punto intermedio, pero con mayor dispersi√≥n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c633e",
   "metadata": {},
   "source": [
    "## Preparaci√≥n de los Datos para el Entrenamiento\n",
    "\n",
    "Antes de entrenar un modelo de Machine Learning, es fundamental preparar los datos de manera adecuada.  \n",
    "En este notebook trabajaremos dos aspectos clave:\n",
    "\n",
    "### 1. Codificaci√≥n de variables categ√≥ricas\n",
    "Los algoritmos de Machine Learning de `scikit-learn` solo trabajan con variables num√©ricas.  \n",
    "Por esta raz√≥n, es necesario transformar la variable categ√≥rica `categoria_proveedor` en n√∫meros que representen cada clase.  \n",
    "\n",
    "Existen dos estrategias comunes:\n",
    "- **Label Encoding**: asigna un n√∫mero entero a cada categor√≠a (0, 1, 2‚Ä¶). Es √∫til para problemas de clasificaci√≥n multiclase como este.  \n",
    "- **One-Hot Encoding**: crea variables binarias (0/1) para cada categor√≠a. Es preferible cuando no queremos introducir un orden artificial entre categor√≠as.\n",
    "\n",
    "En este caso utilizaremos **Label Encoding**, ya que nuestra variable objetivo es la clase de proveedor.\n",
    "\n",
    "### 2. Estandarizaci√≥n de variables num√©ricas\n",
    "Las variables num√©ricas (ej. tiempo de entrega, costos de transacci√≥n) tienen escalas diferentes.  \n",
    "La estandarizaci√≥n permite que todas est√©n en una escala comparable, con media 0 y desviaci√≥n est√°ndar 1.  \n",
    "Esto evita que atributos con valores m√°s grandes dominen el entrenamiento del modelo.  \n",
    "\n",
    "Aunque algunos algoritmos como los √°rboles no necesitan estandarizaci√≥n, otros como regresi√≥n log√≠stica, SVM o redes neuronales s√≠ se benefician de esta normalizaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71237587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df582c",
   "metadata": {},
   "source": [
    "## Estandarizaci√≥n de Variables Num√©ricas\n",
    "\n",
    "En esta secci√≥n aplicamos **StandardScaler** de `scikit-learn` para llevar todas las variables num√©ricas a una misma escala.  \n",
    "Este paso es importante porque muchos algoritmos de Machine Learning (ej. KNN, regresi√≥n log√≠stica, SVM) son sensibles a las diferencias de magnitud entre variables.  \n",
    "\n",
    "El proceso se desarrolla en los siguientes pasos:\n",
    "\n",
    "1. **Selecci√≥n de variables num√©ricas**  \n",
    "   Se extraen todas las columnas excepto la variable objetivo `categoria_proveedor_num`.  \n",
    "\n",
    "2. **Inicializaci√≥n del escalador**  \n",
    "   Se crea una instancia de `StandardScaler()`, que transformar√° los datos aplicando la f√≥rmula:  \n",
    "   \\[\n",
    "   z = \\frac{x - \\mu}{\\sigma}\n",
    "   \\]  \n",
    "   donde \\( \\mu \\) es la media y \\( \\sigma \\) la desviaci√≥n est√°ndar de cada variable.  \n",
    "\n",
    "3. **Ajuste y transformaci√≥n**  \n",
    "   Con `fit_transform()` se calcula la media y desviaci√≥n est√°ndar de cada variable, y luego se aplica la estandarizaci√≥n.  \n",
    "\n",
    "4. **Reconstrucci√≥n del DataFrame**  \n",
    "   Los valores escalados se convierten nuevamente en un `DataFrame`, conservando los nombres de columnas y el √≠ndice original.  \n",
    "\n",
    "5. **Concatenaci√≥n con la variable objetivo**  \n",
    "   Finalmente, las variables estandarizadas se unen con la variable `categoria_proveedor_num` para formar el dataset final `data_final`.  \n",
    "\n",
    "Este dataset estandarizado ser√° el que usemos para entrenar y evaluar nuestros modelos de clasificaci√≥n.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffdef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3838cdf",
   "metadata": {},
   "source": [
    "##  Separaci√≥n de los datos en entrenamiento y prueba\n",
    "\n",
    "Una vez que los datos est√°n preparados y estandarizados, el siguiente paso es dividirlos en dos conjuntos:  \n",
    "\n",
    "- **Conjunto de entrenamiento (train):** usado para ajustar el modelo y permitirle \"aprender\" a partir de los datos.  \n",
    "- **Conjunto de prueba (test):** usado para evaluar el desempe√±o del modelo en datos nuevos que no vio durante el entrenamiento.  \n",
    "\n",
    "### üîπ Pasos realizados en la celda\n",
    "\n",
    "1. **Definici√≥n de variables predictoras y objetivo**  \n",
    "   - `X` contiene todas las variables num√©ricas (predictoras).  \n",
    "   - `y` contiene la variable objetivo `categoria_proveedor_num`, que representa la clase de proveedor.  \n",
    "\n",
    "2. **Divisi√≥n de los datos con `train_test_split`**  \n",
    "   - `test_size=0.2` ‚Üí el 20% de los datos se reserva para prueba y el 80% para entrenamiento.  \n",
    "   - `random_state=16` ‚Üí asegura que la partici√≥n sea reproducible, es decir, siempre se obtendr√° la misma divisi√≥n al ejecutar el c√≥digo.  \n",
    "   - `stratify=y` ‚Üí mantiene la proporci√≥n original de las clases de proveedores en ambos conjuntos, evitando sesgos en el balance de categor√≠as.  \n",
    "\n",
    "3. **Revisi√≥n de tama√±os**  \n",
    "   Con `X_train.shape` y `X_test.shape` confirmamos cu√°ntos registros quedaron en cada conjunto.  \n",
    "\n",
    "\n",
    "\n",
    " Esta separaci√≥n es fundamental para validar que el modelo no solo se ajusta bien a los datos de entrenamiento, sino que tambi√©n generaliza correctamente a datos nuevos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4dbb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eb6ae9",
   "metadata": {},
   "source": [
    "##  Entrenamiento del modelo KNN\n",
    "\n",
    "En esta celda entrenamos un modelo de **K-Nearest Neighbors (KNN)** utilizando la librer√≠a `scikit-learn`.  \n",
    "\n",
    "###  ¬øQu√© es KNN?\n",
    "KNN es un algoritmo de clasificaci√≥n supervisada que asigna a una nueva observaci√≥n la clase m√°s com√∫n entre sus *k* vecinos m√°s cercanos en el espacio de caracter√≠sticas.  \n",
    "- \"Vecinos\" se definen a partir de la **distancia** entre puntos (generalmente Euclidiana).  \n",
    "- El valor de **k** controla cu√°ntos vecinos se consideran para decidir la clase final.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01351b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab192e",
   "metadata": {},
   "source": [
    "## Ejemplo de predicci√≥n con el modelo KNN\n",
    "\n",
    "En esta celda probamos el modelo entrenado con un **proveedor hipot√©tico**, al que se le asignan valores para cada variable.  \n",
    "El flujo es el siguiente:\n",
    "\n",
    "1. Se definen los valores de entrada (tiempo de entrega, confiabilidad, costos y defectos).  \n",
    "2. Se escalan con el mismo `StandardScaler` usado en el entrenamiento.  \n",
    "3. El modelo **KNN** predice la categor√≠a num√©rica del proveedor.  \n",
    "4. Usamos el `LabelEncoder` para traducir esa predicci√≥n a su etiqueta original (*Estrat√©gico, Regular u Ocasional*).  \n",
    "\n",
    "De esta forma, podemos simular distintos escenarios y verificar c√≥mo clasifica el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import numpy as np\n",
    "\n",
    "def predecir_proveedor(tiempo_entrega, confiabilidad, costos_transaccion, defectos_millon):\n",
    "    # Construimos el array con los valores ingresados\n",
    "    X_user = np.array([[tiempo_entrega, confiabilidad, costos_transaccion, defectos_millon]])\n",
    "    X_user_scaled = scaler.transform(X_user)\n",
    "\n",
    "    # Predicci√≥n con el modelo KNN entrenado\n",
    "    prediction = knn.predict(X_user_scaled)\n",
    "    predicted_label = le.inverse_transform(prediction)\n",
    "    \n",
    "    print(\"üìä Categor√≠a de proveedor predicha:\", predicted_label[0])\n",
    "\n",
    "# Sliders interactivos para cada variable\n",
    "interact(\n",
    "    predecir_proveedor,\n",
    "    tiempo_entrega=widgets.FloatSlider(min=1, max=10, step=0.5, value=5, description=\"Entrega (d√≠as)\"),\n",
    "    confiabilidad=widgets.FloatSlider(min=2, max=5, step=0.1, value=3, description=\"Confiabilidad\"),\n",
    "    costos_transaccion=widgets.FloatSlider(min=0.5, max=5, step=0.1, value=2, description=\"Costos\"),\n",
    "    defectos_millon=widgets.FloatSlider(min=0.1, max=3.5, step=0.1, value=1, description=\"Defectos\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509528c3",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n del Modelo KNN\n",
    "\n",
    "Despu√©s de entrenar el modelo KNN con `k=3`, es fundamental medir su desempe√±o para conocer qu√© tan bien clasifica a los proveedores en cada categor√≠a.  \n",
    "En esta celda realizamos la evaluaci√≥n en tres pasos:\n",
    "\n",
    "### 1Ô∏è Predicciones sobre el conjunto de prueba\n",
    "- Con `knn.predict(X_test)` generamos las predicciones para las observaciones reservadas en el conjunto de prueba.  \n",
    "- Estas predicciones se comparan con los valores reales (`y_test`) para calcular m√©tricas de desempe√±o.  \n",
    "\n",
    "### 2Ô∏è Matriz de confusi√≥n\n",
    "- La **matriz de confusi√≥n** nos muestra el n√∫mero de aciertos y errores por clase.  \n",
    "- La diagonal principal indica las predicciones correctas, mientras que los valores fuera de la diagonal corresponden a errores de clasificaci√≥n.  \n",
    "- Utilizamos `ConfusionMatrixDisplay` para visualizarla de manera clara:  \n",
    "  - Filas ‚Üí valores reales (clases verdaderas).  \n",
    "  - Columnas ‚Üí valores predichos (clases asignadas por el modelo).  \n",
    "- Esto nos permite detectar, por ejemplo, si el modelo confunde a proveedores **Regulares** con **Ocasionales**.  \n",
    "\n",
    "### 3Ô∏è M√©tricas de desempe√±o\n",
    "- **Accuracy**: proporci√≥n de predicciones correctas sobre el total.  \n",
    "- **Precision**: de todos los proveedores que el modelo predijo como una categor√≠a, ¬øqu√© porcentaje realmente pertenece a esa clase?  \n",
    "- **Recall (sensibilidad)**: de todos los proveedores que realmente pertenecen a una categor√≠a, ¬øqu√© porcentaje logr√≥ detectar el modelo?  \n",
    "- **F1-score**: balance entre *precision* y *recall*, especialmente √∫til si las clases no est√°n perfectamente balanceadas.  \n",
    "\n",
    "El comando `classification_report` genera estas m√©tricas para cada clase de proveedor (*Estrat√©gico, Regular, Ocasional*) y un promedio general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2bde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ce645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar los objetos entrenados\n",
    "joblib.dump(knn, \"knn_model.pkl\")          # Modelo entrenado\n",
    "joblib.dump(le, \"label_encoder.pkl\")       # Codificador de etiquetas\n",
    "joblib.dump(scaler, \"scaler.pkl\")          # Estandarizador\n",
    "\n",
    "print(\"Modelo, LabelEncoder y StandardScaler guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar los objetos previamente guardados\n",
    "knn_1 = joblib.load(\"knn_model.pkl\")          # Modelo entrenado\n",
    "le_1 = joblib.load(\"label_encoder.pkl\")       # Codificador de etiquetas\n",
    "scaler_1 = joblib.load(\"scaler.pkl\")          # Estandarizador\n",
    "\n",
    "print(\"Modelo, LabelEncoder y StandardScaler cargados correctamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
